# 计算机组成结构（二）

## 第五章

指令周期：读取并执行一条指令的时间，CPI

指令执行过程，先按PC取指令然后PC指向下一条指令

存取操作可用寄存器传送语言描述RTL

CPU可以看做是由数据通路和控制部件构成的

CPU中的寄存器：通用寄存器、地址寄存器？、PC都是用户可见的，IR（存指令，有的时候只存操作码部分，送去译码）、MDR、MAR用户不可见

注意PC，MDR，MAR都是寄存器，状态改变时都需要建立和保持时间

### 数据通路

数据通路是指令的执行部件，是进行数据传送、处理和存储的路径。

元件：组合逻辑（操作）元件，时序逻辑（状态、存储）元件

连接方式：总线方式和分散连接方式

状态元件：n位寄存器由n个边沿触发的D触发器构成

- 暂存寄存器：WE=1且时钟边沿 Data Out=Data In（时钟信号都是统一的，所以需要一个额外的读写信号分别控制寄存器），有点像缓冲器
- 通用寄存器：一个写口，写操作属于时序逻辑，两个读口，读操作属于组合逻辑
- ![image-20220407222057738](https://s2.loli.net/2022/04/07/o6xGDOlWTc4isju.png)



![image-20220331213200042](https://s2.loli.net/2022/03/31/KX6kGxrQyOpNAbR.png)

状态单元的输入信息总是在一个时钟边沿到达后的“Clk-to-Q”时才被写入到单元中，此时的输出才反映新的状态值

时序控制：早期使用三级时序系统，周期，节拍，脉冲（从大到小），现代计算机的时序控制就是用时钟

数据通路由状态元件和操作元件交替组成，操作元件在不关心的那段时间完成操作（设置D），状态元件在时钟触发沿更新状态（Q随D更新）

在下一次边沿到来之前setup的时间状态就不能再变状态了，所以时钟周期= Latch Prop + Longest Delay（最长操作延时） + Setup + Clock Skew(时钟偏移)，下一次操作也不能做得太快影响这一次的状态更新，(Latch Prop + Shortest Delay Path - Clock Skew)  >  Hold Time 

总线设计：

- 单总线（注意是CPU内部的总线，不是外部的）

  ![image-20220408165346299](https://s2.loli.net/2022/04/08/VRl6dBQ5sv4rYOh.png)

  ALU和所有的寄存器都与一条内部的公共总线相连接，总线没有存储功能，某一时刻（一个时钟周期内）只能有一个部件把信息送到总线上

  - 下图是**寄存器内的一位触发器**和内总线相连的情况，寄存器由$R_{in}$和$R_{out}$两个信号控制，$R_{in}=1$，触发器随总线改变，总线的数据送入寄存器，$R_{out}=1$把寄存器的信息送到总线上，单总线上一个时刻只能有一个寄存器$R_{out}=1$

  ![image-20220408095659564](https://s2.loli.net/2022/04/08/2MkEXAK8mCGgLxJ.png)

  ![image-20220408164426654](https://s2.loli.net/2022/04/08/Nqb8sFklOmrc1oa.png)

   时序分析：控制信号R会有一定的延迟Clk-to-Signal，这个延迟一般比寄存器的Latch-prop要长，可以覆盖，Rout有效后三态门开始启动，经过一定的时间启动完成后就开始传输，传输完成后被写入的寄存器需要建立时间来做准备，之后还需要保持一段时间（注意状态改变才需要建立和保存时间，流出数据的寄存器状态没变不需要这些）

  - 两操作数的运算

    ![image-20220408171458086](https://s2.loli.net/2022/04/08/PETAi4HtKGgdUpz.png)

    两个存储器不可能同时把两个操作数放到总线上传给ALU，所以必须先暂存下来一个（不存的话下一时刻就没了)，所以需要Y，第二步一个数据从Y流出，一个数据从R2流出经过总线传给ALU，该时钟周期内不能再上传数据到总线了，所以只能把结果暂存在Z中，加法操作需要3个时钟周期（<font color='cornflowerblue'>不清楚的时候就看总线图，数据从哪儿流到哪儿，每个周期只能在总线上流一次</font>）（Y和ALU没有经过总线相连，不用写$Yout$）

    <font color='cornflowerblue'>时序分析</font>：ALU时延在总线传输时延之后，注意加法运算分成的三步，第一步和第三步都是寄存器之间的数据流动，只有第二步是需要在上图中加入ALU时延的

  - 存字和取字，分为同步和异步两种，异步：主存操作的时候CPU需要停下来等待，所以需要**控制信号WMFC**，主存完成操作后向CPU发送一个MFC完成信号，CPU就继续执行后续操作，同步存储器会在读信号发出固定的几个时钟周期内准备好数据，read和write时间固定，不需要WMFC，MFC信号也需要通过总线传输，所以read,MFC占一个时钟周期，而同步的Read之后还可以进行一次占用总线的操作，这就需要合理的安排利用后面的时间发送控制信号了

    指令寄存器IR，MDR存数据，MAR存地址，取字操作先把地址从寄存器读到MAR中，然后read（按MAR访问内存取数据到MDR中），最后写到寄存器，存字就是读地址和数据，然后写入内存

    Rout,OP,Zin中如果涉及到了内存访问，Read/Write的时间比OP的时间更长，以它们为准

- 三总线

  ALU三条线分别与三根总线相连，两根总线传送源操作数，一根传结果，可在一个时钟周期内完成加法操作

#### MIPS设计

通用寄存器组

数据存储器（内存）和指令存储器都看做理想存储器

ALU部件，操作控制信号ALUctr，ALU进行以下7种操作: addu（lw,sw,addiu，加法运算不判溢出，ALU不用管带不带符号，运算规则一样，加法直接算，减法变反+1变成加法） , add，or , subu(beq判0操作)，sub，sltu（无符号数比大小），slt（带符号数比大小），sltu和slt都不判断溢出，ALUctr至少有三位。

ALU并不知道是在做有符号还是无符号数的运算，是设计者知道，然后利用相应的标志位

取指令部件：先取指令，然后更新PC，下地址逻辑：顺序PC<-PC+4，转移PC<-目标地址

![image-20220408155147168](https://s2.loli.net/2022/04/08/OeNYA54IRtZFVhm.png)

![image-20220412105531032](https://s2.loli.net/2022/04/12/IV25QhYK9brautg.png)

先把所有可能的操作码都输出，之后再判断用不用

增加多路选择器，指令译码后产生控制信号，使用控制信号控制完成多种功能

R型：从寄存器组中（双口）读，输入到ALU中运算，结果写入寄存器组中

I型：增加一个输入imm的接口，选择符号或逻辑扩展和subB进行选路，输入到ALU中，lw，sw：ALU的计算结果作为访问memory的地址，beq：这时的imm没有输入ALU，输入ALU的是两个寄存器中的数，ALUstr=subu，判0标志和imm送入下地址逻辑，地址永远是4的倍数，PC可以省略最低两位的00，只保留30bit，取指令的时候加上最后的00，从而+4简化成+1，imm16符号拓展成30位即可，不用*4了

![image-20220412104840307](https://s2.loli.net/2022/04/12/Xc3Gei5gx7F9nzb.png)

<font color='red'>！！</font>注意跳转也是要先+1（+4）再跳转的

J型：再加一条路接target（26）和PC的高四位组成30位的目标地址，连上多路选择器输入PC

j target是绝对寻址，但是范围有限，只能在j指令所在的一页（2^28^bits=256MB）中跳转，页面号就是PC的高四位，程序不可能超过太大的范围

分支需要PC+4，跳转不需要

![image-20220412104758060](https://s2.loli.net/2022/04/12/aBLSQhlRrmZq4AO.png)

![image-20220412105822614](https://s2.loli.net/2022/04/12/93htoXsPWxcbevj.png)

### 性能

单周期处理器每条指令都在一个周期内完成，即CPI=1

时钟周期的倒数叫主频 

lw执行时间最长，假设存储器读写是一样长的时间，lw多了一次回写，是时钟周期的关键路径，时钟周期=PC锁存延迟（PC更新延迟）+取指令时间+寄存器取数时间（控制信号产生的时间被覆盖了）+ALU延迟+存储器取数时间+寄存器建立时间（PC建立时间被覆盖了）+时钟偏移

<font color='red'>！！</font>写是时序逻辑，所以在这个周期内准备好写入数据和控制信号，时钟沿到来也就是下个周期的时候才会写入，所以计算操作执行时间的时候，读就计算组合逻辑操作需要的时间，写就计算寄存器建立set-up时间就行了。还要注意哪些是只能先后执行的，哪些是能并行执行的

![image-20220412195329360](https://s2.loli.net/2022/04/12/PtfmUL2AX3Kzc9W.png)

单周期取指令最长的执行时间作为是时钟周期，意味着短指令的时间利用率较低

所以可以考虑用多周期的处理器，时钟周期固定，时钟周期数可变

### 控制器

#### 硬连线

控制单元主要包含指令译码器，其输入是指令操作码OP，输出的是控制信号

新指令读出后进行指令译码，更新控制信号

add和addu的差别就在于**是否产生溢出标志**，u不产生，溢出标志和RegWr使能信号用与门连接（不是有无符号，因为ALU不需要知道自己在算什么，送进来的imm16做相应的拓展就行）

Brand，Jump，RegWr，MemWr不能任意，不写的时候写使能就必须封住，不需要写入寄存器的时候，RegDst就可以任意，不需要16imm的时候Extop就可以任意

相对寻址要不要+4主要是看电路设计，相对寻址主要用于分支指令中，取操作数用的都是基址（imm表示偏移量，符号扩展），MIPS不管是跳转还是顺序都会先做+4，所以相对寻址也就变成了相对PC+4

![image-20220412195700394](https://s2.loli.net/2022/04/12/14i5MmPEDJvd3g6.png)

R型指令op=000000，除了ALUctr以外其他控制信号都相同，功能由func决定，所以由主控制器产生其他控制信号，使用一个局部的ALU来处理func产生ALUctr

把逻辑表转换成逻辑表达式，就把最小项（1）或起来，相当于写成积之和式

eg： $ALUSrc=(op==00 1101) | (op==10 0011) | (op==10 1011)$

op==00 1101或100011或101011时，ALUSrc=1

![image-20220414104050764](https://s2.loli.net/2022/04/14/xohNHtKyVMns7bX.png)



#### 微程序

硬件实现出错无法修改，成本太高，所以就产生了用软件实现的微程序控制，微程序灵活可维护但速度慢

每条微指令是一个0/1序列，包含若干个微命令

微程序存在只读存储器中（称为控制存储器），因此又叫固件，固化的软件，输入是指令和条件码，输出是微命令

CPU从控存中取出每条指令对应的微程序，在时钟的控制下，按照一定的顺序执行每条微指令

![image-20220414192108796](https://s2.loli.net/2022/04/14/prVXNSmybBgEUJa.png)

微指令分为微操作码（就是若干微命令）和微地址码

**微命令编码**

水平型：相容微命令尽量多地安排在一条微指令中，包括不译法： 一位对应一个微命令（控制信号），不需译码，微操作码的长度与所有微命令的个数相当；字段直接编码法：分字段，互斥的微操作组合在同一字段内，字段间接编码法

垂直型：一条微指令只控制一、二个微命令，包括最短编码法



**下地址确定**

![image-20220414192605117](https://s2.loli.net/2022/04/14/lviHIh2W5pF1UCS.png)

断定法下条指令的地址被保存在uAR中

增量法中只有转移控制字段，断定法中还有下地址字段

### 异常和中断处理

中断和异常的检查是在什么时候

中断：CPU中止原来正在执行的程序，转到处理异常情况或特殊事件的程序去执行，执行后再返回到原被中止的程序处（断点）继续执行

- 内部异常：CPU内部，硬故障/程序性，有些是补救后可继续执行的，有些只能终止进程
  - 故障：执行指令过程中发生的异常事件，处理完后可能返回断点继续执行，也可能终止执行，断点是发生故障的指令的地址
  
  - 自陷：预先安排的事件，如单步跟踪，系统调用，断点是下条指令的地址 ，但是当自陷指令是转移指令的时候，直接返回转移目标地址继续执行

    ”断点“设置和单步跟踪的实现：当终端标志和跟踪标志同时有效时，每条指令都设置成了陷阱，转移去执行“单步跟踪处理程序”，该程序清除两个标志，执行当前指令并显示执行结果
  
  - 终止：硬故障事件，调出中断服务程序来重启操作系统。
  
- 外部中断：是一种I/O方式

异常处理：

1. 关中断，不再接收新的中断，中断/异常允许状态位清0

2. 保护断点和程序状态，将断点和程序状态保存到堆栈或特殊寄存器中。

3. 识别异常事件并转异常处理：硬件修改，在取指令部件中，更新PC之前加一个多路选择器根据是否有中断请求选路，再加一个写入（保存）断点的电路

   转移可以是转到一个地方，然后在那个地方用软件处理决定下一步的操作，也可以用硬件存储一个异常信号对应的转移地址的表，直接查表转移



## 第六章

不使用流水线的单周期的处理器大部分操作是串行执行的，前一个完成了才进行后面的，很多空闲的时间没有利用

要把数据通路分成多个部分，多条指令同时执行，每个指令使用一个部分，每次往前推进一个部分，这样时钟周期就缩短到执行时间最长的部分的指令执行时间

采用流水线后每一条指令的执行时间会变长，但是指令吞吐率提高，效率提高

一般流水线分段越多（越深），主频越大

流水线的效率：M段的流水线，每段执行的时间是T，则N条指令执行的总时间是（N+M-1）*T

各操作阶段花费的时间均衡时节约的时间最多

长度一致，格式规整，装入/存储型适合指令流水线

### 流水线数据通路

为了不产生冲突，要把五个阶段都保留 ，对齐，虽然有的阶段其实不用执行，但是还是安排空的动作或者做了但通过信号控制结果不使用nop，等待过该阶段的时间

每个阶段的交界处都要有寄存器，存放各阶段的执行结果，否则下一个时钟到来结果就丢失了

![image-20220423170342721](https://s2.loli.net/2022/04/23/eZqK5UajWuXhMyt.png)

![image-20220426104913711](https://s2.loli.net/2022/04/26/gDq5FONl8HTSdUp.png)

还要注意取指令部件和执行部件的内部构造

IF/ID寄存器存放指令和PC+4；

ID/Ex，存放目的寄存器编号（Rt，Rd），从寄存器中取出的数，imm16（先不管指令是什么类型，用不用，先取出来），PC+4，<font color='red'>func（局部控制器在Ex段）</font>；

EX/Mem，存放<font color='red'>转移目标地址（注意不是PC+4，是经过adder之后PC+4+4*imm16，选择在取指令部件中完成）</font>，ALU计算得到的结果，标志位zero,overflow，选出的目的寄存器编号，寄存器中取出的数（sw指令）

Mem/Wr，从内存中取出来的数据，ALU计算出的结果，目的寄存器编号，overflow（要在回写阶段判断是否写入）

跳转指令：beq指令，PC+4在取指令阶段完成，正常情况下取指令完后就更新PC成PC+4，比较两个数之后才能判断是否转移，所以ALU阶段产生Zero标志位之后，Mem阶段才能更新PC，ALU是比较两个数，PC+4+4*imm16在一个与ALU独立的adder上完成，也是在Ex阶段。jump指令是PC（不是PC+4）和target拼接后，存入EX/Mem寄存器中，也是在Mem阶段跳转（书上是这样讲的，但为了避免控制冒险，应该可以在产生控制信号之后就跳转

Ex：R型指令，func、ALUop和R-type共同作用决定ALUsrc的过程在Ex阶段完成，所以func、R-type要一只保留到Ex阶段，立即数的拓展是在Ex阶段完成的

### 流水线控制信号

控制信号（译码产生的主控信号）也会保存在流水段寄存器中，不消耗就一直向后面传递，每个阶段取自己要用的就行

PC和流水段寄存器不需要写使能，每个周期完都一定会更新

Ifecth阶段和Dec/Reg阶段都没有控制信号

注意控制信号branch在Mem阶段使用，RegDst在ALU阶段使用，没有在回写阶段使用，因为可以早点决定目的寄存器是谁，减小流水段寄存器的空间

![image-20220512101356715](https://s2.loli.net/2022/05/12/XMe3mbV1lrQpj5O.png)

### 冒险

结构冒险：同一个部件被处于不同阶段的不同指令使用，硬件竞争

Wr和ID的冲突，分开指令存储器和数据寄存器；把寄存器的读口和写口分开，利用时钟上升和下降沿两次触发，做到半个周期读，半个写，先写后读。

数据冒险：前面指令的结果还没产生，后面的指令就要用

1. 插入空操作，软件（nop）

2. 插入气泡，硬件（stall）

3. 转发，只要是算出来了，可以不等存到该存的地方，直接用，从Ex/Mem寄存器流出输入到ALU（差一个周期），从Ex/Wr寄存器流出输入到ALU（差一个周期），输入到DM

   只有lw不能直接转发，最后才取出来，还要加阻塞

4. 通过编译程序优化指令顺序

下一条指令取的数要等上一条指令回写后才能取，不用转发需要插入3个nop，如果把寄存器的读写口分开，半周期完成就插入2条nop

插入nop不是让指令停在上一阶段，就是停在取数阶段：1. 将ID/Ex流水段寄存器中的控制信号全部清零 2. IF/ID中的维持不变 3. PC维持不变，让后一条指令被延迟取出 

数据冒险的具体检测方法：查看Ex/Mem，Mem/Wr流水段寄存器中存放的回写目的寄存器的编号，和ID/Ex流水段寄存器中待读取的寄存器编号是否相同，RegWr控制信号是否为1，load-use的检测：看ID/Ex和IF/ID中的寄存器编号是否相同，MemRead信号是否为1

注意该阶段的控制信号和需要用到的数据信息是存在前一个流水段寄存器中的，下一个时钟周期新产生的信息才会更新寄存器

控制冒险：由于指令执行顺序改变引发的流水线阻塞

1. 分支冒险

   先做预测，按预测的结果执行，如果预测出错再做其他处理

   缩短分支延迟，提早判断，如果出错就清除已经进入的错误指令

2. 中断或异常引发的冒险

<font color='cornflowerblue'>T：流水线分析</font>

分析冒险：1. sw不会导致数据冒险，因为是存内存，不是存到寄存器里 2. beq，jump导致的控制冒险不要忽略了

怎么插入nop和转发

多条指令，分析某个周期或周期结束后的状态

首先分析（画图）该周期每条指令运行到什么阶段。<font color='red'>！！注意有冲突，不要忽略了必须插入的nop</font>

## 第七章

存取方式

随机存取：按地址访问存储单元，每个地址的译码时间相同（cache和主存）

顺序存取：信息按顺序存放和读出，容量大但读取慢（磁带）

直接存取：先随机定位访问存储信息的区域，在区域内顺序存取（磁盘）

相联存取：不是按地址，是用访问信息的内容特征作索引

断电后的数据保存

外存是非易失性的，内存是易失性，内存与CPU直接相连，外存只能将数据先传送给内存，内存再传给CPU，执行程序时程序和数据全部被拉入内存

ROM、磁表面存储器、光存储器非易失，RAM易失

![image-20220426113607163](https://s2.loli.net/2022/04/26/m3jEpxKiQWuAbMS.png)



地址线36位，CPU可寻址范围为0~2^36^-1，即主存地址空间为64GB（按字节编址时）

但是主存容量，即实际的主存大小并不一定是64GB，看你装多大的

频率k=10^3^，容量k=2^10^

存储器的性能：每单位价格



### 随机存取存储器

#### RAM（可读写）

**基本存储元件：**

动态RAM用单管的栅极电容存储信息，需要刷新（充电保持数据不变），静态RAM用六管双稳态触发器存储信息，不用刷新

动态的读出是破坏性的，读后要重新写，”再生“

静态集成度低，但读写速度快，做cache，动态做主存



**译码方式**

一维译码适用于容量较小的SRAM，二维适合动态

二维译码：横纵都选通才能访问，速度快、拆成二维后地址线减少

多个位平面，每个位平面接的地址线都一样，但是数据线不一样

数据线即位线，地址线即字线，分为行和列

芯片容量，指的是总容量，二维平面上的存储单元数*位数



每出现新一代DRAM芯片，即行地址和列地址各增加一位（一般是正方形（周长最小）行和列同时增加），容量至少提高到4倍



**DRAM的刷新**（区分刷新和再生）

按行刷新，一般是先读出来，再重写

刷新方式：

集中刷新，刷新多少行就需要多少个读写周期，死区

分散刷新，在每次读写之后刷新，但存储周期会变长

异步刷新，一个刷新周期内刷新所有行，间隔=刷新周期/行数



存储周期是连续两次读或写操作之间的最小时间间隔=读出时间/写入时间+两次存取之间的稳定恢复时间（一般大于读和写的时间）

CPU与存储器之间的通信（就是之前的主存读写操作）

异步：握手，需要发送”完成“信号

同步：CPU和主存由统一时钟信号控制，无需应答信号（如“完成”），主存总是在确定的时间内准备好数据，使用SDRAM

SDRAM是同步存储芯片

#### ROM（只读）

存放一些固定的程序，还可作为控制存储器，存放微程序

flash 闪存，非易失，可读写，U盘和存储卡

![image-20220428223011883](https://s2.loli.net/2022/04/28/vgcnGhdjaNmHCqY.png)

![image-20220428112136410](https://s2.loli.net/2022/04/28/T7hI5yVbvjmKSrz.png)



### 存储器的扩展

字扩展，几块芯片拼成一块更大的，加地址线控制片选

地址引脚复用：为了减少引脚的个数，把行地址和列地址用同一组引脚分时传送

位扩展，几块芯片叠成一块更厚的

位扩展的时候要注意主存以什么为单元编址，n位编址，n位以内一定是同时读，不需要片选，传输宽度扩展成2^k^n位的时候就要用k位来片选（不是只选一个，感觉更像是使能信号）了，因为可能由于不对齐存放或者读short等原因不用一次读完整个传输宽度，每片都和单独的数据线相接，地址线选出每个行、列交叉处的n个位平面的数据同时读写

eg：p247，图中的每个芯片（方形）本来就包含8个位平面，然后又用了8个芯片来位扩展，所以8*8=64位，主存地址27位，高24位作为片内地址24位，这里的片选不对，这和字扩展只选一片的选法不一样，这里是在8个字节里选任意个字节，不能只用3位，至少要8位，也可以直接用CPU传信号过来选而不是在地址中选

这也解释了为什么要对齐存放，如果int放在8,9,10,11，就只用访问1次取出，10,11,12,13就要访问两次

片内编址方式，连续和不连续，这里采用不连续的交叉编址方式，可以同时读取，效率更高

注意片选信号放的位置，如果放在高位，那么同一片内每一位的地址（片选地址+片内地址）就是连续的，如果放在低位，同一片内每一位的地址（片内地址+片选地址）就是不连续的

![image-20220506172512874](https://s2.loli.net/2022/05/06/qJiM7fvBKN5AgxY.png)

![image-20220506173744136](https://s2.loli.net/2022/05/06/PfVApIhEBNQxoK5.png)



<font color='cornflowerblue'>T：芯片扩展</font>

先算需要几片芯片，字扩展和位扩展

字扩展是一定会用片选的

一般没有很严谨，传输宽度上需要位扩展时也当作不同的片选来处理了，所以一般根据编址方式求出主存地址的位数，求出片内的地址位数之后剩下的就用做片选位

容量指的就是位平面大小*位数，是总的了

<font color='cornflowerblue'>T：给出区域对应的地址，解释地址译码逻辑</font>

注意给出地址后把地址变化层二进制就是每位对应一根地址线不能乱匹配

算一下地址范围多大，需要怎样扩展

连续编址的话就是高位是片选，低位是片内地址

可以分组描述片选逻辑（用地址位表示片选信号）+用于片内选址的位数

eg：课堂练习，指导书p4

<font color='cornflowerblue'>T 画逻辑图：</font>

字扩展-地址线：片内选址+片选，片内选址取最小的单元，所有片都连一样的片内地址线，片选信号是一种使能信号，只有一位，每片连的信号不一样，是高位地址经过译码产生的

位扩展，每个位平面连不同的数据线，相同的地址线和片选信号，所以有位扩展的位线就应该分开接，字线接一样的

控制线，访存控制和读写控制，3-8译码器出来一般是低有效

字扩展横着画，位扩展竖着画

片内的选址线、数据线、控制线都是复用的，因为只有一片会被选中

![image-20220428113937951](https://s2.loli.net/2022/04/28/F1wGUPjehianO53.png)

指导书p5

都是1K的芯片，低10位是片内选址，最后两片RAM接相同的片选信号

除去低10位片内选址还剩6位，MREQ要占用一个使能端，所以剩下有一位要不接入译码器，单独连入逻辑门

![image-20220517173751533](https://s2.loli.net/2022/05/17/Kdn3UAvl6gHy4r8.png)

### 高速缓存

程序和数据的访问有时间（同一数据短时间内被多次访问）和空间（相邻的数据在较短的时间间隔内被相继访问）局部性，因此可以考虑缓存主存的一个区域

cache用在主存和CPU之间，大多数情况下，CPU能直接从这个高速缓存中取得指令和数据，而不必访问主存，有关cache的处理一般都是硬件完成的

如果访问信息不在cache中（缺失或失靶(miss)），就在cache中找一块不常用的，把要访问的一块复制到cache中替换这一块，同时把这一块送到CPU中

主存块(Block)，Cache也被分成相同大小的块，称为Cache行（line）或槽（Slot）

cache：有效位|标记|数据

cache需要一个有效位标记，开机或复位时，V=0，更新替换后V=1

主存块与cache的映射：

- 直接映射

每个主存块映射到Cache的固定行

模映射：cache行号=块地址 mod cache行数（2^k^），所以就等于块地址取低k位

主存地址：标记|cache行号|块内地址

替换是固定的，不需要考虑替换算法，如果两块主存的模相同，后被用到的就会替换之前的主存块，不管之前的是否空闲，这样失靶会很多，会产生频繁的 Cache装入

块字节数不能设置得太小，太小就会导致无法充分利用空间局部性，而且冲突概率较大，交换频繁，也不能太大，增加了读取时间而且行数减少，缺失率也会上升

<font color='cornflowerblue'>T 主存地址划分和访问过程：</font>

主存块的大小+**按什么编址**->块内地址（最低位）的位数

数据区大小/主存块大小=cache行数->cache行号的位数（块地址的低k位）

余下来的高位作为标记

计算cache总容量，数据区大小+（标记+有效位+修改位（回写）+计数位（LRU））*行数

<font color='red'>！！cache组号和行号是直接用偏移寻址可以找到的，cache中不需要记录</font>

![image-20220507102947193](https://s2.loli.net/2022/05/07/is9C6HPfa7lc4jq.png)

访问过程：

首先根据cache行号找到对应的行，检查有效位和标记，然后根据块内地址计算偏移

<font color='cornflowerblue'>！已知主存地址（单元号）或块号求cache行号</font>

不知道内存地址的位数也可以算

方法一：mod

已知单元号，注意先要算<font color='red'>块号=单元号/块大小</font>，不能直接用整个地址mod行数。如果告诉块号就直接mod

方法二：直接变成二进制内存地址（注意块号和单元号存放的位置不同），取中间对应cache行号的几位

注意一般会用16进制表示，2变16，从低位开始四位一划分，高位补0，所以位数不同时表示成的形式可能不同，一定要注意要取几位，然后变成二进制来比

- 全相联映射

每个主存块可装到cache中的任意一行

整个主存块号都作为标记，按内容访问，标记|块内地址

优点是可以随机替换空闲的块，没有冲突缺失，缺点是标记占用cache的空间很大，每行都需要一个比较器才能并行比较标记，开销也极大



- 组相联映射

就是把行换成组，行/路数=组数2^k^，所以就有k位的cache组号

组内的标记（n路）同时比较

![image-20220507104310940](https://s2.loli.net/2022/05/07/jWduhKk94C6XYrI.png)

关联度：主存块映射到cache中可能存放的位置个数

当cache大小、主存块大小一定时

关联度越低，命中率越低，标记为所占的空间开销越小，判断是否命中花费的开销越小，命中时间越短。



替换算法：

- 先进先出FIFO，记录最早进入的一块
- 最近最少用LRU，替换访问频率最低的一块

LRU是一种栈算法，它的命中率随组的增大而提高。

实现方法是给cache行设定一个计数器，计数值称为LRU位

命中时，被访问行的计数器置0，**比其低**的计数器加1，其余不变。
未命中且该组未满时，新行计数器置为0，其余全加1。
未命中且该组已满时，计数值最大的一行中的主存块被替换，新行计数器置为0，其余加1

注意这个计数不是记录的使用频率，是和频率相反的，计数越大越少使用

当分块局部化范围(即：某段时间集中访问的存储区)超过了Cache存储容量时，命中率变得很低。如果又遇到颠簸的情况就更低了

当遇到颠簸时，组相连+LRU替换策略的缺失率可能比直接映射还高，可能颠簸的周期大于组的大小，命中率就会降为0



写策略：

写的时候要让主存和cache之间保持一致

全写法

主存和缓存同步更新，写开销较大

命中的时候直接同时写，没有命中的时候更新主存块中的内容，然后将更新后的主存块装入cache（写分配法）或者不装

回写法

可能一个主存块在短时间内会被多次修改，所以先不写主存，只写缓存（如果不命中就先把主存块放进缓存然后写），设置一个修改位记录被修改了没有，等到该主存块被替换的时候再将更新写入主存中

### 虚拟存储

把**地址空间**和**主存容量**的概念区分开来，寻址空间可以比实际的主存容量大，把主存放不下的部分保存到磁盘上

解决了两个问题：编程空间不受限制 ，多道程序可以安全有效的共享主存

#### 分页存储

内存被分成固定长且比较小的存储块（页框、实页、物理页）

每个进程也被划分成固定长的程序块（页、虚页、逻辑页）

程序块可装到内存中可用的存储块中，无需用连续页框来存放一个进程

操作系统为每个进程生成一个页表，通过页表(page table)实现逻辑地址向物理地址转换（Address Mapping ）

每个进程的虚拟地址空间是私有的

- 存储和访问流程“请求分页”

把主存看成是CPU与硬盘之间的缓存

在发生程序或数据访问失效(缺页)时，由**操作系统**进行主存和磁盘之间的信息交换。

通过软件处理缺页，因为访问磁盘本来就很慢，瓶颈在那里，没必要再用快的方式了

主存和磁盘之间的采用回写策略保持一致性

![image-20220507115259195](https://s2.loli.net/2022/05/07/cxkyJufAQs7EWM9.png)

- 页表结构

为了提高命中率，虚页和页框之间使用全相联

装入位（对应的实页有没有装到主存里）|修改位|替换控制位|访问权限位|禁止缓存位|其他|实页号

页表中不用存虚页号，虚页使用偏移寻址，页表的基地址存储在寄存器中，然后页号相当于偏移量，寻址找到，而不是一项项对比

页表存放了整个虚拟空间，各进程有相同虚拟空间，故理论每个进程的页表是一样大的。不过程序可能没有用到整个虚拟空间的地址，可能出现实页号为空的情况，“空洞”

地址分为两部分，高位是页号，低位是页内偏移量，页框和页的大小相同，所以页内偏移量相等，页表实现了虚页号和页框号的对应，所以只要通过查询页表将虚页号替换成物理页号，再和页内偏移量拼起来就转换成了物理地址，转换过程由存储器管理部件MMU（硬件）来完成

![image-20220512200348292](https://s2.loli.net/2022/05/12/4Dzi2ZV1ugosjdE.png)



- 快表

把经常要查的页表项（但实页可能在cache或主存中，注意命中就意味着装入位=1，不可能没有装入主存）放到Cache中，这种在Cache中的页表项组成的页表称为TLB（快表）

TLB可以看作是CPU和页表之间的缓存，所以建立的是TLB表项和页表项之间的映射，映射也有全相联、组相联、直接三种

TLB标记是什么？应该是页表项的索引的一部分，页表项的索引其实是虚页号，虽然没有写在表项内，所以TLB标记就是虚页号的最高几位

把虚拟地址划分成：标记|TLB组号或行号|页内偏移量，前两项合起来是虚页号

TLB中的页表项：标记|主存页表项

cache映射用的地址是主存的物理地址，不是虚拟地址

页表中存了全部，TLB中存了部分，所以TLB命中页表一定命中，但是实际上不会再去查页表

可能需要访问主存0-3次

![image-20220510112622578](https://s2.loli.net/2022/05/10/CaKS5ywLErdgYU6.png)

<font color='cornflowerblue'>T 综合考察访存过程：</font>

先查TLB，没有再查页表，把虚拟地址换成物理地址，是否在cache中，不在就移到cahce中访问

查询TLB，标记是虚页号的高位，组号是低位，先求组号，只能在对应的组中找，然后求标记<font color='red'>多少位</font>，对比的时候注意<font color='red'>2变16进制都是从后往前划分的,，不足的在前面补0！！</font>或者全变成二进制来比，最后看有效位 

查询页表，第一项对应基地址，没说就对应0

查询cache

怎么映射？怎么划分？

#### 分段存储

按程序的逻辑结构划分成多个相互独立的部分

段的长度可变，所以段表比页表多一个段长表项

分段对于程序员来说是不透明的

#### 段页式

程序按模块分段，段内再分页



## 第八章

### I/O设备

外部设备：输入设备、输出设备、外部存储器

I/O性能

吞吐率：单位时间内从系统输入/输出多少数据或操作

响应时间：在多长时间内完成请求的任务

![image-20220613122022301](https://s2.loli.net/2022/06/13/uDp6BI5PYxtjLUT.png)

磁盘存储器分硬盘和软盘两种，软盘被U盘淘汰；U盘和固态硬盘由闪存（可擦除的flash ROM）制成

硬盘存储器由磁记录介质、硬盘驱动器、硬盘控制器（前两者之间的接口）组成

磁盘的读写原理：

写1：线圈通以正向电流，使呈N-S状态，写0：线圈通以反向电流，使呈S-N状态

读时磁头不动，磁盘转动

磁盘结构：

磁道：同心圆，道密度

扇区：磁道的分段（扇形），位密度

![image-20220519104628211](https://s2.loli.net/2022/05/19/4iPrdtsyx8anmYB.png)

![image-20220519105740504](https://s2.loli.net/2022/05/19/EMRjp7eBdq9tnhZ.png)

容量：未格式化，总容量，用位密度`*`周长来算；格式化，数据区容量，用扇区个数*数据量

响应时间：排队时延+控制器时间+寻道时间+旋转等待时间+数据传输时间

以扇区为单位进行读写，读写操作分为寻道，旋转等待和读写三部分，所以后三部分时间之和称为平均存取时间，数据传输时间比前两部分要短很多，内部数据传输速率=每秒转速`*`内圆周长`*`位密度，旋转等待时间平均取半圈，但是实际可能更短，因为程序的局部性；外部数据传输速率与磁盘的转速无关，指磁盘接口与磁盘缓存之间进行数据交换的速率。

冗余磁盘阵列：

优点：1. 组织起来，提高容量；2. 采用交叉存储实现并行存取，提高速率；2. 冗余磁盘技术来进行错误恢复

小条带交叉：一个I/O请求分布在所有盘中，并行存取，提高数据传输率

大数据块交叉：数据量小的I/O请求只访问一个物理盘，多个物理盘相应多个I/O请求

交错因子，逻辑相邻的数据分布的距离最好与等待时间内磁盘转过的距离一致

RAID0 无冗余，可交叉

RAID1 镜像盘实现1对1冗余，取时间短的读，并行写

RAID2 用海明校验码生成多个冗余校验盘，纠正一位，检验两位

RAID3 、RAID4 用一个冗余盘存放的奇偶校验位，3是小条带交叉，4是大数据块交叉

RAID5 奇偶校验块分布在各个磁盘中

恢复：根据异或运算的可交换性

![image-20220519211449381](https://s2.loli.net/2022/05/19/qNomFWlxnwuLaXP.png)

更新：为了计算新的校验位，需要读取之前的数据和校验位，两次读，两次写

![image-20220519211555251](https://s2.loli.net/2022/05/19/cYJpkrLMg9dDOoR.png)

RAID6 二维奇偶校验

RAID7 带cache



### 总线结构

系统总线通常由一组控制线、一组数据线和一组地址线构成。也有些总线没有单独的地址线，地址信息通过数据线来传送，这种情况称为数据/地址复用。

现在一般是点到点（无需总线裁决），串行（无需位与位之间同步），异步

**并行/串行传输**（和常规的意义不太一致）

并行：一个方向同时传输多位数据信号，故位与位需同步！
串行：一个方向只传输一位数据信号，无需在位之间同步！但是可以有多个方向（方向可以看作通道）传递数据的各位，多个方向之间不用同步。

**定时方式**

同步：用统一的时钟信号来同步，协商好在哪个时钟周期做什么。要以最慢的操作为准，还有时钟偏移问题

异步：前一个信号的结束就是下一个信号的开始

**传送方式**

非突发：先传地址，在传数据

突发：再进行数据块传输时，给出首地址，后续数据的地址是默认前面的地址+1

作业T5，主存和磁盘之间传送数据

n字块的传输方式，就是一次事务传输n字块

写入外设事务分为：向主存发送首地址，访问主存存取数据，向磁盘传送数据（传送时间与总线宽度有关），空闲（读取外设就是先传送，后访存），其中向CPU传输数据和访存读数据是不冲突的，可以同时进行，所以当一次读取的字块数较多时，一般平均速率更快

![image-20220601112829345](https://s2.loli.net/2022/06/01/1aSeTM2JLkvpZHG.png)

总线的最大数据传输率
对于同步总线，总线带宽计算公式： B=W×F/N
W-总线宽度（位数）；F-总线时钟频率；N-完成一次数据传送所用时钟周期数。
F/N实际上就是总线工作频率，现在的总线可在一个周期内传输多次数据，工作频率通常比总线时钟频率快



CPU外部总线：CPU（前端）总线：FSB（并行同步），存储器总线，I/O总线：XT、ISA、EISA、VESA、PCI（点对点串行）、AGP

CPU内部总线：QPI（点对点串行），Intel将北桥集成到CPU中，QPI可以双向传输数据，所以带宽=每秒传输次数×每次传输的有效数据×2  

桥位于多线交汇的地方，是交换数据的芯片，如果没有桥，连线就会混乱，速度不一致，发生碰撞。北桥的速度很快，南桥较慢

![image-20220519114735263](https://s2.loli.net/2022/05/19/zujO3ME718aLZy9.png)



### I/O接口

各类外设控制器或DMA控制器、中断控制器

功能：数据缓冲，数据缓冲寄存器，以达到主机和外设工作速度的匹配；错误或状态检测，状态/控制寄存器；控制和定时；数据格式转换；与主机和设备通信

IO接口中设置缓冲寄存器的作用有两方面，1. 如果没有缓冲，CPU就要频繁地查询或者中断，甚至频率要比主频还高，无法实现；2. 外设的传输速度比总线能支持的传输速度慢很多，不用缓冲外设就会一直占用总线，使用缓冲区后只是缓冲区放满了就挪用一个周期

编址：I/O端口就是IO接口中的寄存器，编址就是给这些可访问的端口（常用的是数据缓冲寄存器和状态/控制寄存器）编址，程序员只需要掌握CPU如何寻找到端口地址，I/O接口与外设之间的通信协议（包括具体怎么寻找到外设的地址等）不需要掌握

- 独立编址方式：

  通过不同的读写控制信号IOR、 IOW和 MEMR、 MEMW来控制对I/O 端口和存储器的读写。
  一般I/O端口比存储器单元少，所以选择I/O端口时，只需少量地址线。I/O和内存的访问指令的格式不统一，指令系统必须设计专门的I/O指令。译码简单，速度快，但不灵活

- 统一编址方式：

  MEMR或MEMW有效，就意味着IOR或IOW应该无效，所以参与片选的高位地址线和MEMR/MEMW取与非得到控制IO空间中某一片的IOR/IOW（低有效），即IOR/IOW是由访存指令产生的。速度慢，会占用部分内存空间

  

### I/O传输方式

- 程序直接控制

  无条件传送：对一些简单设备在规定时间内进行输入和输出，通过程序来定时，同步传送数据

  条件传送：轮询方式，询问是否准备就绪，是否完成工作

  定时查询

  独占查询：CPU与外设串行工作，在I/O工作的时间内，CPU不停地在轮询，CPU用100%的时间为I/O服务，效率低、速度慢，适合于慢速设备

- 中断I/O

  **需要CPU干预**，它就通过中断请求通知CPU

  从外设中读出的数据先放在缓冲器里，放满之后CPU再来取就很快了，CPU只是在收到请求（启动和结束）的时候取处理和控制I/O，这个时间是很短的，然后I/O设备自己工作，CPU去做其他的事情，CPU占用率比较小

  中断检测在一条指令执行完后进行

  中断响应：

  1. 关中断（禁止中断）！即：将中断允许（触发器）标志清0

  2. 保护现场和断点信息：
    
     现场：一些用户可见的工作寄存器中存放着程序执行到断点处的现行值
     
     断点信息：返回的PC（有可能是当前指令、下一条指令或跳转指令）和程序状态（PSW程序状态字）
     
     一般是保存到堆栈或特殊寄存器（EPC、EPSW)中
     
  2. 识别异常事件，并根据<font color='green'>响应优先级</font>进行判优
    
  2. 转到具体的异常处理程序执行
     有两种不同的方式：软件方式一般比硬件慢
     （1）软件识别（MIPS采用） ：设置一个异常状态寄存器（MIPS中为Cause寄存器），用于记录异常原因。操作系统使用一个统一的异常处理程序（MIPS的入口为0x8000 0180） ，该程序按优先级顺序查询异常状态寄存器，识别出异常事件。
     （2）硬件识别（向量中断）（80x86采用）：用专门的硬件查询电路按优先级顺序识别异常，得到一个“中断类型号”，根据此号，到中断向量表中读取对应的中断服务程序的入口地址（类似偏移寻址）。
     
     中断过程包括中断响应和中断处理，中断响应的结果就是调出相应的中断服务程序，前两步都是硬件实现的
     
     ![image-20220526113101413](https://s2.loli.net/2022/05/26/Jqc4CDuI3vgTGrR.png)

  中断处理：

  在执行中断处理的过程中可能会被新的中断请求打断，形成多重中断，中断请求保存在中断请求寄存器中，但是并不是所有的新的请求都能打断现在执行的中断处理程序，需要根据<font color='green'>中断处理优先级</font>

  两种优先级的比较

  中断响应优先级：由查询程序或者中断判优电路决定，在响应阶段，就是在主程序上按响应优先级

  中断处理优先级：通过设置中断屏蔽字，进入了中断处理程序之后清除就该程序的中断请求，就是一进来就当它处理完了，并把自己和比自己处理优先级低的程序的屏蔽字都设为1（1屏蔽，0开放），所以就是在处理程序中不管响应优先级，按处理优先级处理

  实际上现在基本只使用中断响应优先级

  ![image-20220526114911198](https://s2.loli.net/2022/05/26/1SupfO8bhGZYoPi.png)

  <font color='cornflowerblue'>T 根据两种优先级画CPU运动轨迹图</font> eg：作业T13

  1. 每次进入程序后都先要判断是否被处理优先级更高的打断，列出所有的中断请求来判断
  1. 如果当前还有更高处理优先级的一定会被立刻打断，所以在处理过程中来了新的中断，指的是打断都结束了，又回到了这里的长段的过程
  1. 被打断的过程画短线，处理程序画长线

中断方式虽然可以并行，但是需要保护断点和现场、开关中断、设置屏蔽字，CPU处理开销还是很大，而且CPU还需要通过lw/sw指令向主存存取数据，如果速度太快还会造成数据丢失，所以更高速的外设适用DMA

- DMA方式

  外设直接和主存进行数据交换，数据不通过CPU，只需要CPU让出总线（I/O总线和存储器总线）
  
  ![image-20220531191843412](https://s2.loli.net/2022/05/31/lC83OVDuy1R5maP.png)
  
  DMA方式的操作步骤：
  
  信号传送：DMA控制器收到外设的DMA请求后，向CPU请求总线，CPU完成现行机器周期后发出总线响应，DMA控制器收到后向外设发出DMA响应
  
  ![image-20220531195033193](https://s2.loli.net/2022/05/31/now8Cs1qiATMI4f.png)
  
  1. DMA初始化（由CPU执行初始化程序完成，使用查询或中断方式）：准备内存区，设置传送参数，发送“启动DMA传送”命令
  
     ![image-20220531192916768](https://s2.loli.net/2022/05/31/e7KZnbfasPC6DQT.png)
  
     字计数器，传输一个字就-1，用于判断数据是否传输完成
  
  2. DMA数据传送（CPU不参与，由DMA控制器控制）
  
  3. DMA结束处理：当字计数器为0时，DMA控制器向CPU发出“DMA结束”中断请求，CPU转入中断服务程序
  
  DMA和CPU可能出现争用主存，处理方法：(1) CPU停止法(成组传送)，(2) 周期挪用(窃取)法(单字传送，窃取的是主存的存储周期，不是总线周期），(3)交替分时访问法，实际情况下由于cache的存在能避免多数访存冲突。参见突发方式和非突发方式，数据的读取用的是主存，传输用的是总线，它们是不冲突的，可以同时进行以提高效率，所以成组传输的时候可以连续读取内存，停止CPU是合理的，单字访问中间过程的时间比较多，读取并不连续，所以使用窃取
  
  DMA与存储系统：地址统一问题，I/O一致性问题
  
  DMA方式和中断方式的区别
  
  - 数据传送，DMA方式由硬件（DMA控制器）完成，中断方式由软件完成（CPU执行中断服务程序）
  - DMA除了开始和结束需要中断CPU，数据传输过程中不需要中断CPU，只要请求总线的控制权
  - 中断响应在一个指令周期结束后；而DMA响应是在一个总线周期后
  - DMA只能用做传输，但中断还可应用于其他很多场景，比如异常处理

总线时钟频率（总线工作频率=总线时钟频率*一周期内的数据传送次数），外设的频率，CPU主频这三者相互独立，毫无关系

<font color='cornflowerblue'>T：计算与外设进行数据传送占整个CPU时间的百分比</font>

eg：作业T16

1. 查询和中断方式一般会使用缓冲器先存储外设传出的数据，外设一次传的数据量有限，需要多次传送，定时查询的定时一般是传输一次的时间

   不错过数据，至少需要查询/中断处理多少次？外设的传输速率是RBps，每次中断传输LB数据，要求没有任何数据被错过，从时间角度，外设传输一次数据需要的时间L/Rs，即每隔L/Rs申请一次中断，如果不用重新启动，传送周期就是L/Rs，CPU占用率=一个周期中CPU的工作时间/传送周期，或者算总时间也可以；从频率的角度，每秒传输RB数据，就需要R/L次中断，CPU占用率=1s被处理中断所用的周期数/1s内的CPU周期数，当需要的中断频率大于CPU主频时就不能使用中断请求方式了。如果硬盘仅有部分时间在工作，那还要乘上工作时间所占的百分比

2. 外设在两次传输之间是否需要重新启动（块传输还是字符传输），不需要则两次传输之间没有空隙

   如果忽略启动时间，如果能刚好在上一次传输完成时让设备启动则时间不变（查询可能可以做到），中断方式必须在中断处理程序中启动设备，所以肯定会隔一段时间

3. 外设工作时间，CPU工作时间，处理总时间

   对于查询方式和中断方式，由于查询的周期和外设的数据传输周期未必能对齐（独占查询），且最后一次处理时间是单独的，处理总时间一般略大于外设工作时间

   对于DMA方式，外设和CPU的工作完全是分开的，处理总时间=外设工作时间+CPU工作时间
   
4. 独占查询方式，看开头几个字节，中间的形成周期，最后几个字节


